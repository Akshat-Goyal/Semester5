{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roll No: 2018101075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwxWcO7fqb-L"
   },
   "source": [
    "# Excercise - Multi-class classification of MNIST using Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcygblmOmQDZ"
   },
   "source": [
    "In binary perceptron, where $\\mathbf{y} \\in \\{-1, +1\\}$, we used to update our weights only for wrongly classified examples.\n",
    "\n",
    "The multi-class perceptron is regarded as a generalization of binary perceptron. Learning through iteration is the same as the perceptron. Weighted inputs are passed through a multiclass signum activation function. If the predicted output label is the same as true label then weights are not updated. However, when predicted output label $\\neq$ true label, then the wrongly classified input example is added to the weights of the correct label and subtracted from the weights of the incorrect label. Effectively, this amounts to ’rewarding’ the correct weight vector, ’punishing’ the misleading, incorrect weight\n",
    "vector, and leaving alone an other weight vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "import math\n",
    "import gif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223975,
     "status": "ok",
     "timestamp": 1596984132348,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "gNkGLnbjTY-s"
   },
   "outputs": [],
   "source": [
    "# Setting the seed to ensure reproducibility of experiments\n",
    "np.random.seed(11)\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "def one_hot(a):\n",
    "  b = -1 * np.ones((a.size, a.max()+1))\n",
    "  b[np.arange(a.size), a] = 1\n",
    "  return b\n",
    "\n",
    "# Loading digits datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "Y = digits.target\n",
    "Y = one_hot(Y)\n",
    "\n",
    "# Adding column of ones to absorb bias b of the hyperplane into X\n",
    "X = digits.data\n",
    "bias_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, bias_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223957,
     "status": "ok",
     "timestamp": 1596984132353,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "0BPvc5P8KvrM",
    "outputId": "233f09b1-7641-4c60-c21d-74a2264f8bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  (1257, 65)\n",
      "Validation dataset:  (180, 65)\n",
      "Test dataset:  (360, 65)\n",
      "Y shape:  (1257, 10)\n"
     ]
    }
   ],
   "source": [
    "# Train-val-test data\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, shuffle=True, test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = 0.12517)\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape)\n",
    "print(\"Validation dataset: \", X_val.shape)\n",
    "print(\"Test dataset: \", X_test.shape)\n",
    "print(\"Y shape: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223939,
     "status": "ok",
     "timestamp": 1596984132358,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "QPJZdeDtUfoy",
    "outputId": "66a50417-5c21-4158-f029-20ef755e50f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.reset_orig();\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[10])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2KVp57S1Zah"
   },
   "source": [
    "#### Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(d, n):\n",
    "#     W = np.zeros((d, n))\n",
    "    W = np.random.normal(size=[d, n])\n",
    "    return W\n",
    "\n",
    "def normalize(X):\n",
    "    mu = np.mean(X, axis=0, keepdims=True)\n",
    "    sigma = np.std(X, axis=0, keepdims=True)\n",
    "    sigma[sigma == 0] = 1\n",
    "    X = (X - mu) / sigma\n",
    "    return mu, sigma, X\n",
    "\n",
    "# returns accuracy of binary class data\n",
    "def binary_class_accuracy(X, y, w):\n",
    "    return np.mean(np.where((X@w).ravel() >= 0, 1, -1) == y)\n",
    "\n",
    "# binary classifier\n",
    "def linear_perceptron(X, y, X_val, y_val, epochs=1000, lr=1e-3, epsilon=1e-5):\n",
    "    m, d = X.shape\n",
    "    w = init_weights(d, 1)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_w = w.copy()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        w_new = w.copy()\n",
    "        for i in range(m):\n",
    "            if float(y[i] * X[i:i+1,:] @ w) < 0:\n",
    "                w_new += lr * y[i] * X[i:i+1,:].T\n",
    "        w = w_new.copy()\n",
    "        \n",
    "        val_acc = binary_class_accuracy(X_val, y_val, w)\n",
    "        if best_val_acc  <= val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_w = w.copy()\n",
    "            \n",
    "        if not epoch % (epochs // 10):\n",
    "            print(f\"Epoch {epoch}: train acc: {binary_class_accuracy(X, y, w)}: val acc: {val_acc}\")\n",
    "        \n",
    "    return best_w\n",
    "\n",
    "# training one vs all classifier\n",
    "def train(X, Y, X_val, Y_val, epochs=50, lr=2*1e-3):\n",
    "    m, d = X.shape\n",
    "    _, n = Y.shape\n",
    "    \n",
    "    W = np.zeros((d, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        print(f\"Training for class {i} vs all for {epochs} epochs for {lr} learning rate\")\n",
    "        W[:, i:i+1] = linear_perceptron(X, Y[:, i], X_val, Y_val[:, i], epochs, lr)\n",
    "        print(f\"Training for class {i} vs all ends\")\n",
    "        \n",
    "    return W\n",
    "\n",
    "def predict(X, W):\n",
    "    if len(X) == 1:\n",
    "        X = X.reshape((1, X.shape[0]))\n",
    "    pred = X @ W\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    return pred.ravel()\n",
    "\n",
    "def accuracy(X, Y, W):\n",
    "    pred = predict(X, W)\n",
    "    return np.mean(Y[np.arange(pred.shape[0]), pred] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for class 0 vs all for 1000 epochs for 0.1 learning rate\n",
      "Epoch 0: train acc: 0.9005568814638027: val acc: 0.9166666666666666\n",
      "Epoch 100: train acc: 0.9976133651551312: val acc: 0.9944444444444445\n",
      "Epoch 200: train acc: 0.9976133651551312: val acc: 0.9944444444444445\n",
      "Epoch 300: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 400: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 500: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 600: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 700: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 800: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 900: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Training for class 0 vs all ends\n",
      "Training for class 1 vs all for 1000 epochs for 0.1 learning rate\n",
      "Epoch 0: train acc: 0.898170246618934: val acc: 0.9055555555555556\n",
      "Epoch 100: train acc: 0.9737470167064439: val acc: 0.9888888888888889\n",
      "Epoch 200: train acc: 0.8727128082736675: val acc: 0.8888888888888888\n",
      "Epoch 300: train acc: 0.9801113762927606: val acc: 0.9888888888888889\n",
      "Epoch 400: train acc: 0.9809069212410502: val acc: 0.9888888888888889\n",
      "Epoch 500: train acc: 0.9785202863961814: val acc: 0.9777777777777777\n",
      "Epoch 600: train acc: 0.9777247414478918: val acc: 0.9888888888888889\n",
      "Epoch 700: train acc: 0.9809069212410502: val acc: 0.9833333333333333\n",
      "Epoch 800: train acc: 0.9626093874303898: val acc: 0.9777777777777777\n",
      "Epoch 900: train acc: 0.9785202863961814: val acc: 0.9777777777777777\n",
      "Training for class 1 vs all ends\n",
      "Training for class 2 vs all for 1000 epochs for 0.1 learning rate\n",
      "Epoch 0: train acc: 0.9093078758949881: val acc: 0.8666666666666667\n",
      "Epoch 100: train acc: 1.0: val acc: 1.0\n",
      "Epoch 200: train acc: 1.0: val acc: 1.0\n",
      "Epoch 300: train acc: 1.0: val acc: 1.0\n",
      "Epoch 400: train acc: 1.0: val acc: 1.0\n",
      "Epoch 500: train acc: 1.0: val acc: 1.0\n",
      "Epoch 600: train acc: 1.0: val acc: 1.0\n",
      "Epoch 700: train acc: 1.0: val acc: 1.0\n",
      "Epoch 800: train acc: 1.0: val acc: 1.0\n",
      "Epoch 900: train acc: 1.0: val acc: 1.0\n",
      "Training for class 2 vs all ends\n",
      "Training for class 3 vs all for 1000 epochs for 0.1 learning rate\n",
      "Epoch 0: train acc: 0.8997613365155132: val acc: 0.9111111111111111\n",
      "Epoch 100: train acc: 0.9896579156722355: val acc: 1.0\n",
      "Epoch 200: train acc: 0.9856801909307876: val acc: 0.9944444444444445\n",
      "Epoch 300: train acc: 0.9904534606205251: val acc: 1.0\n",
      "Epoch 400: train acc: 0.9856801909307876: val acc: 0.9944444444444445\n",
      "Epoch 500: train acc: 0.9920445505171042: val acc: 0.9888888888888889\n",
      "Epoch 600: train acc: 0.9936356404136834: val acc: 0.9944444444444445\n",
      "Epoch 700: train acc: 0.9936356404136834: val acc: 0.9944444444444445\n",
      "Epoch 800: train acc: 0.9928400954653938: val acc: 0.9944444444444445\n",
      "Epoch 900: train acc: 0.9968178202068417: val acc: 0.9944444444444445\n",
      "Training for class 3 vs all ends\n",
      "Training for class 4 vs all for 1000 epochs for 0.1 learning rate\n",
      "Epoch 0: train acc: 0.8989657915672236: val acc: 0.9277777777777778\n",
      "Epoch 100: train acc: 0.994431185361973: val acc: 0.9888888888888889\n",
      "Epoch 200: train acc: 0.9976133651551312: val acc: 0.9944444444444445\n",
      "Epoch 300: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 400: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 500: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 600: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 700: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 800: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 900: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Training for class 4 vs all ends\n",
      "Training for class 5 vs all for 1000 epochs for 0.1 learning rate\n",
      "Epoch 0: train acc: 0.8989657915672236: val acc: 0.8444444444444444\n",
      "Epoch 100: train acc: 0.9968178202068417: val acc: 0.9833333333333333\n",
      "Epoch 200: train acc: 0.9952267303102625: val acc: 0.9722222222222222\n",
      "Epoch 300: train acc: 0.9976133651551312: val acc: 0.9666666666666667\n",
      "Epoch 400: train acc: 1.0: val acc: 0.9666666666666667\n",
      "Epoch 500: train acc: 1.0: val acc: 0.9666666666666667\n",
      "Epoch 600: train acc: 1.0: val acc: 0.9666666666666667\n",
      "Epoch 700: train acc: 1.0: val acc: 0.9666666666666667\n",
      "Epoch 800: train acc: 1.0: val acc: 0.9666666666666667\n",
      "Epoch 900: train acc: 1.0: val acc: 0.9666666666666667\n",
      "Training for class 5 vs all ends\n",
      "Training for class 6 vs all for 1000 epochs for 0.1 learning rate\n",
      "Epoch 0: train acc: 0.858392999204455: val acc: 0.8277777777777777\n",
      "Epoch 100: train acc: 0.9896579156722355: val acc: 0.9944444444444445\n",
      "Epoch 200: train acc: 0.9960222752585521: val acc: 0.9944444444444445\n",
      "Epoch 300: train acc: 0.9968178202068417: val acc: 0.9944444444444445\n",
      "Epoch 400: train acc: 0.9984089101034208: val acc: 0.9944444444444445\n",
      "Epoch 500: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 600: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 700: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 800: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Epoch 900: train acc: 1.0: val acc: 0.9944444444444445\n",
      "Training for class 6 vs all ends\n",
      "Training for class 7 vs all for 1000 epochs for 0.1 learning rate\n",
      "Epoch 0: train acc: 0.8997613365155132: val acc: 0.9055555555555556\n",
      "Epoch 100: train acc: 0.9936356404136834: val acc: 0.9833333333333333\n",
      "Epoch 200: train acc: 0.9960222752585521: val acc: 0.9833333333333333\n",
      "Epoch 300: train acc: 0.9960222752585521: val acc: 0.9833333333333333\n",
      "Epoch 400: train acc: 1.0: val acc: 0.9833333333333333\n",
      "Epoch 500: train acc: 1.0: val acc: 0.9833333333333333\n",
      "Epoch 600: train acc: 1.0: val acc: 0.9833333333333333\n",
      "Epoch 700: train acc: 1.0: val acc: 0.9833333333333333\n",
      "Epoch 800: train acc: 1.0: val acc: 0.9833333333333333\n",
      "Epoch 900: train acc: 1.0: val acc: 0.9833333333333333\n",
      "Training for class 7 vs all ends\n",
      "Training for class 8 vs all for 1000 epochs for 0.1 learning rate\n",
      "Epoch 0: train acc: 0.09944311853619729: val acc: 0.08333333333333333\n",
      "Epoch 100: train acc: 0.8918058870326173: val acc: 0.8611111111111112\n",
      "Epoch 200: train acc: 0.9459029435163087: val acc: 0.9333333333333333\n",
      "Epoch 300: train acc: 0.9482895783611774: val acc: 0.9277777777777778\n",
      "Epoch 400: train acc: 0.964200477326969: val acc: 0.95\n",
      "Epoch 500: train acc: 0.9681782020684169: val acc: 0.95\n",
      "Epoch 600: train acc: 0.9403341288782816: val acc: 0.9611111111111111\n",
      "Epoch 700: train acc: 0.9657915672235481: val acc: 0.95\n",
      "Epoch 800: train acc: 0.9045346062052506: val acc: 0.9166666666666666\n",
      "Epoch 900: train acc: 0.9610182975338106: val acc: 0.9611111111111111\n",
      "Training for class 8 vs all ends\n",
      "Training for class 9 vs all for 1000 epochs for 0.1 learning rate\n",
      "Epoch 0: train acc: 0.9005568814638027: val acc: 0.9\n",
      "Epoch 100: train acc: 0.9745425616547335: val acc: 0.9777777777777777\n",
      "Epoch 200: train acc: 0.9801113762927606: val acc: 0.9833333333333333\n",
      "Epoch 300: train acc: 0.9801113762927606: val acc: 0.9888888888888889\n",
      "Epoch 400: train acc: 0.9872712808273667: val acc: 0.9888888888888889\n",
      "Epoch 500: train acc: 0.9689737470167065: val acc: 0.9666666666666667\n",
      "Epoch 600: train acc: 0.9920445505171042: val acc: 0.9888888888888889\n",
      "Epoch 700: train acc: 0.9832935560859188: val acc: 0.9888888888888889\n",
      "Epoch 800: train acc: 0.9896579156722355: val acc: 0.9888888888888889\n",
      "Epoch 900: train acc: 0.9824980111376292: val acc: 0.9888888888888889\n",
      "Training for class 9 vs all ends\n"
     ]
    }
   ],
   "source": [
    "W = train(X_train, Y_train, X_val, Y_val, 1000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy 0.9681782020684169\n",
      "Val set accuracy 0.95\n",
      "Test set accuracy 0.9527777777777777\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set accuracy {accuracy(X_train, Y_train, W)}\")\n",
    "print(f\"Val set accuracy {accuracy(X_val, Y_val, W)}\")\n",
    "print(f\"Test set accuracy {accuracy(X_test, Y_test, W)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZQQfFFOrqST3"
   ],
   "name": "LinearPerceptron_draft4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (cvit)",
   "language": "python",
   "name": "cvit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
